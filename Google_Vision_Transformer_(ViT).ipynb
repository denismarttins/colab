{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google Vision Transformer (ViT)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsyK3mL2Si6Mp5ZOgvxRu0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denismarttins/colab/blob/main/Google_Vision_Transformer_(ViT).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruCGulvkHmAU"
      },
      "outputs": [],
      "source": [
        "#INSTALANDO AS BIBLIOTECAS\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
        "from PIL import Image\n",
        "import requests"
      ],
      "metadata": {
        "id": "LVOAwnpkGMDt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link = input(\"Put your link here: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9-e2ABSL_LM",
        "outputId": "a50394f2-ce47-4f95-bb45-632f3ca213bb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Put your link here: https://ichef.bbci.co.uk/news/640/cpsprodpb/1615F/production/_108236409_gettyimages-1094812112.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = link"
      ],
      "metadata": {
        "id": "WKd-qDFtGiif"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch16-224')"
      ],
      "metadata": {
        "id": "GJFQcVIoJqnb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViTForImageClassification.from_pretrained('google/vit-large-patch16-224')\n",
        "inputs = feature_extractor(images=image, return_tensors='pt')\n",
        "output = model(**inputs)\n",
        "logits = output.logits"
      ],
      "metadata": {
        "id": "BR6Y6syGJzZ-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Your result is:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJCQnQLIJXfg",
        "outputId": "bb5b03a9-be91-4513-a409-5a99d536b005"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your result is: academic gown, academic robe, judge's robe\n"
          ]
        }
      ]
    }
  ]
}